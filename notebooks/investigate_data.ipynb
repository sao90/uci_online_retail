{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Investigate UCI retail data\n",
    "\n",
    "this notebook investigates the dataset from UCI, and summarizes key parts of it, that should be handled in data cleaning\n",
    "(it assumes a time series forecasting project will be conducted on the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path().resolve().parent))\n",
    "\n",
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from src.data_processing.data_loader import DataLoader\n",
    "from src.data_processing.data_cleaner import DataCleaner\n",
    "\n",
    "load_dotenv()\n",
    "DB_FILE = os.getenv('DB_FILE')\n",
    "DB_INPUT_TABLE_NAME = os.getenv('DB_INPUT_TABLE_NAME')\n",
    "DB_OUTPUT_TABLE_NAME = os.getenv('DB_OUTPUT_TABLE_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('/Users/soo/repos/private/uci_online_retail/data/pipeline_runs/cleaned_data.parquet')\n",
    "from src.data_processing.data_splitter import DataSplitter\n",
    "from src.log_config import setup_logging\n",
    "setup_logging()\n",
    "data_splitter = DataSplitter()\n",
    "train, test, features = data_splitter.run(\n",
    "    df=df,\n",
    "    date_column='InvoiceDate',\n",
    "    target_column='Quantity',\n",
    "    days_in_test_split=7\n",
    ")\n",
    "\n",
    "# print(f'Train first and last days: {train[\"InvoiceDate\"].min()} - {train[\"InvoiceDate\"].max()}')\n",
    "# print(f'Test first and last days: {test[\"InvoiceDate\"].min()} - {test[\"InvoiceDate\"].max()}')\n",
    "# print(f'Feature first and last days: {features[\"InvoiceDate\"].min()} - {features[\"InvoiceDate\"].max()}')\n",
    "\n",
    "# print(f'all dates in test: {test[\"InvoiceDate\"].unique()}')\n",
    "# print(f'all dates in features: {features[\"InvoiceDate\"].unique()}')\n",
    "# print(f'all dates in train: {train[\"InvoiceDate\"].unique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Run data cleaner class\n",
    "\n",
    "findings:\n",
    "\n",
    "\n",
    "InvoiceNo values containing letters (other than 'C' for cancelled) suggests these are not proper sales transactions.\n",
    "\n",
    "\n",
    "StockCode could should be a 5-digit integral number uniquely assigned to each product. \n",
    "It contains values with letters as well. \n",
    "\n",
    "e.g. \n",
    "- POST = Postage\n",
    "- DOT = DOTCOM POSTAGE\n",
    "- M = MANUAL\n",
    "- PADS = Pads to match all cushions\n",
    "- S = samples\n",
    "- gift_<> = Gift voucher\n",
    "- C2 = CARRIAGE\n",
    "- BANK CHARGES = Bank Charges\n",
    "- B = Adjust bad debt\n",
    "- AMAZONFEE = AMAZON FEE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with DataCleaner(db_path=DB_FILE) as cleaner:\n",
    "    exploration_df = cleaner.run(source_table=DB_INPUT_TABLE_NAME, target_table='exploration', countries=['United Kingdom'])\n",
    "\n",
    "exploration_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary tables\n",
    "\n",
    "exploration_df['revenue'] = exploration_df['Quantity'] * exploration_df['UnitPrice']\n",
    "# count of articles, mean(quantity, revenue and price) and std-dev(quantity, revenue and price) \n",
    "summary_df = exploration_df.agg({\n",
    "    'InvoiceNo': 'nunique',\n",
    "    'StockCode': 'nunique',\n",
    "    'Quantity': ['mean', 'std'],\n",
    "    'UnitPrice': ['mean', 'std'],\n",
    "    'revenue': ['mean', 'std']\n",
    "})\n",
    "\n",
    "most_sold = exploration_df.groupby('Description').agg({'Quantity': 'sum', 'revenue': 'sum'})\n",
    "\n",
    "exploration_df['date'] = pd.to_datetime(exploration_df['InvoiceDate']).dt.date\n",
    "bussiest_days = exploration_df.groupby('date').agg({'Quantity': 'sum', 'revenue': 'sum'})\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "ax = bussiest_days['revenue'].plot(figsize=(12,6), color='blue', label='Revenue')\n",
    "bussiest_days['Quantity'].plot(figsize=(12,6), secondary_y=True, color='orange', ax=ax, alpha=0.7, label='Quantity')\n",
    "ax.set_ylabel('Revenue')\n",
    "ax.right_ax.set_ylabel('Quantity')\n",
    "\n",
    "# Combine legends from both axes\n",
    "lines1, labels1 = ax.get_legend_handles_labels()\n",
    "lines2, labels2 = ax.right_ax.get_legend_handles_labels()\n",
    "ax.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.title(f\"Daily Revenue and Quantity Sold. Correlation: {bussiest_days['revenue'].corr(bussiest_days['Quantity']):.2f}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uci_online_retail-3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
